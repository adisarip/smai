{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the data sets\n",
    "def get_data_sets():\n",
    "    # class labels C1=\"+1\" C2=\"-1\" appended in the last columns\n",
    "    data_set_1 = [[ 3,  3,  1],\n",
    "                  [ 3,  0,  1],\n",
    "                  [ 2,  1,  1],\n",
    "                  [ 0,  2,  1],\n",
    "                  [-1,  1, -1],\n",
    "                  [ 0,  0, -1],\n",
    "                  [-1, -1, -1],\n",
    "                  [ 1,  0, -1]]\n",
    "\n",
    "    data_set_2 = [[ 3,  3,   1],\n",
    "                  [ 3,  0,   1],\n",
    "                  [ 2,  1,   1],\n",
    "                  [ 0,  1.5, 1],\n",
    "                  [-1,  1,  -1],\n",
    "                  [ 0,  0,  -1],\n",
    "                  [-1, -1,  -1],\n",
    "                  [ 1,  0,  -1]]\n",
    "    \n",
    "    return np.array(data_set_1), np.array(data_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the data sets\n",
    "def plot_data_set_1(slope, intercept):\n",
    "    c1_x1 = [3,3,2,0]\n",
    "    c1_x2 = [3,0,1,2]\n",
    "    c2_x1 = [-1,0,-1,1]\n",
    "    c2_x2 = [1,0,-1,0]\n",
    "    \n",
    "    plt.title(\"Data Set 1\")\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.plot(c1_x1, c1_x2, \"o\", label=\"C1\")\n",
    "    plt.plot(c2_x1, c2_x2, \"o\", label=\"C2\")\n",
    "\n",
    "    x = np.linspace(-5, 5, 10)\n",
    "    y = slope*x + intercept\n",
    "    plt.plot(x, y)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the data sets\n",
    "def plot_data_set_2(slope, intercept):\n",
    "    c1_x1 = [3,3,2,0]\n",
    "    c1_x2 = [3,0,1,1.5]\n",
    "    c2_x1 = [-1,0,-1,1]\n",
    "    c2_x2 = [1,0,-1,0]\n",
    "    \n",
    "    plt.title(\"Data Set 2\")\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.plot(c1_x1, c1_x2, \"o\", label=\"C1\")\n",
    "    plt.plot(c2_x1, c2_x2, \"o\", label=\"C2\")\n",
    "\n",
    "    x = np.linspace(-5, 5, 10)\n",
    "    y = slope*x + intercept\n",
    "    plt.plot(x, y)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Traing Least Square Error weights\n",
    "def train_lse_weights(data_set, weights):\n",
    "    \n",
    "    # separating features and class labels\n",
    "    data_set_features = np.array(data_set[:,:-1])\n",
    "    data_set_labels   = np.array(data_set[:,[-1]])\n",
    "\n",
    "    # get the dimensions of the data set\n",
    "    n_datasets, n_features = data_set_features.shape\n",
    "    # assume a learning rate of 1.0\n",
    "    learning_rate = 1.0\n",
    "\n",
    "    for i in range(n_datasets):\n",
    "        x_i = data_set_features[i]\n",
    "        y_i = data_set_labels[i]\n",
    "        w_dot_x = np.dot(weights, x_i)\n",
    "        \n",
    "        # calculate the product y*f(x) -> y_t(w_t.x_t) for misclassification\n",
    "        if (y_i * w_dot_x) <= 0:\n",
    "            weights += learning_rate * (y_i - w_dot_x) * x_i\n",
    "\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute linear classifier using \"Least Square Error\" approach\n",
    "def compute_lse_classifier(data_set, num_epochs):\n",
    "\n",
    "    # adding the bias multipliers in data set\n",
    "    n_datasets = data_set.shape[0]\n",
    "    bias_vector = np.ones(n_datasets).reshape(n_datasets,1)\n",
    "    data_set = np.hstack((bias_vector, data_set))\n",
    "\n",
    "    # initialize the weight vector\n",
    "    weights = np.zeros(data_set.shape[1] - 1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        weights = train_lse_weights(data_set, weights)\n",
    "\n",
    "    # computing m and b for the linear classifier y = mx + b\n",
    "    # where m=(-w_1/w_2) and b=(-w_0/w_2)\n",
    "    b = -weights[0]/weights[2]\n",
    "    m = -weights[1]/weights[2]\n",
    "\n",
    "    return m, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute linear classifier using \"Fisher's LDA\" approach\n",
    "def compute_lda_classifier(data_set, class_labels, num_epochs):\n",
    "\n",
    "    n_features = data_set.shape[1] - 1\n",
    "    S_W = np.zeros((n_features,n_features))\n",
    "    S_B = np.zeros((n_features,n_features))\n",
    "    data_set_features = {}\n",
    "    mean_vectors = {}\n",
    "\n",
    "    #1.compute the mean column vectors\n",
    "    for label in class_labels:\n",
    "        #extract the chunk of features from the data set related to a class\n",
    "        #create a dictionary of key=class_label value=class_data_set\n",
    "        data_set_features[label] = np.array([row[:-1] for row in data_set if row[-1]==label])\n",
    "        #create a dictionary of mean column vectors\n",
    "        #axis=0 is mean computed vertically in the data set\n",
    "        mean_vectors[label] = np.mean(data_set_features[label], axis=0).reshape(n_features,1)\n",
    "\n",
    "    #2.computing the within class scatter matrix : S_W\n",
    "    for label in class_labels:\n",
    "        S_i = np.zeros((n_features,n_features))\n",
    "        for x in data_set_features[label]:\n",
    "            #making column vectors for features and mean\n",
    "            x  = x.reshape(n_features,1)\n",
    "            m = mean_vectors[label].reshape(n_features,1)\n",
    "            #computing scatter matrix of current class\n",
    "            S_i += (x - m).dot((x - m).T)\n",
    "        S_W += S_i\n",
    "        \n",
    "    #3.computing between class scatter matrix\n",
    "    m1 = mean_vectors[class_labels[0]].reshape(n_features,1)\n",
    "    m2 = mean_vectors[class_labels[1]].reshape(n_features,1)\n",
    "    S_B = (m1-m2).dot((m1-m2).T)\n",
    "\n",
    "    #4.find eigen values and eigen vectors the matrix S_W(inv)*S_B\n",
    "    eigen_values, eigen_vectors = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
    "    \n",
    "    print(eigen_values)\n",
    "    print(eigen_vectors)\n",
    "    \n",
    "    #5.sorting eigen vectors in decreasing order of eigen values\n",
    "\n",
    "    #6.projecting data onto the eigen vector corresponding to lasrgest eigen value\n",
    "    \n",
    "    #7.running perceptron algorithm on the projected data to find the linear classifier\n",
    "    \n",
    "    #8.return slope and intercept of the linear classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lse():\n",
    "    #get data sets\n",
    "    data_set_1, data_set_2 = get_data_sets()\n",
    "    \n",
    "    slope1, intercept1 = compute_lse_classifier(data_set_1, 10)\n",
    "    slope2, intercept2 = compute_lse_classifier(data_set_2, 10)\n",
    "    \n",
    "    plot_data_set_1(slope1, intercept1)\n",
    "    plot_data_set_2(slope2, intercept2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lda():\n",
    "    #get the data sets\n",
    "    data_set_1, data_set_2 = get_data_sets()\n",
    "    \n",
    "    class_labels = [1,-1]\n",
    "    compute_lda_classifier(data_set_1, class_labels, 10)\n",
    "    compute_lda_classifier(data_set_2, class_labels, 10)\n",
    "    \n",
    "    #plot_data_set_1()\n",
    "    #plot_data_set_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.02697095e+00  -5.55111512e-17]\n",
      "[[ 0.74651327 -0.5547002 ]\n",
      " [ 0.66537052  0.83205029]]\n",
      "[ 0.86128171  0.        ]\n",
      "[[ 0.78102704 -0.52145001]\n",
      " [ 0.62449721  0.85328183]]\n"
     ]
    }
   ],
   "source": [
    "#run_lse()\n",
    "run_lda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "[[ 9.  9.]\n",
      " [ 9.  9.]]\n",
      "[[ 18.   9.]\n",
      " [  9.   9.]]\n",
      "[[ 22.  11.]\n",
      " [ 11.  10.]]\n",
      "[[ 22.  11.]\n",
      " [ 11.  14.]]\n",
      "[[ 22.  11.]\n",
      " [ 11.  14.]]\n"
     ]
    }
   ],
   "source": [
    "data_set_1 = [[ 3,  3],\n",
    "              [ 3,  0],\n",
    "              [ 2,  1],\n",
    "              [ 0,  2]]\n",
    "\n",
    "data_set_1 = np.array(data_set_1)\n",
    "\n",
    "scatter_matrix = np.zeros((2,2))\n",
    "print(scatter_matrix)\n",
    "\n",
    "for row in data_set_1:\n",
    "    row = row.reshape(2,1)\n",
    "    scatter_matrix += row.dot(row.T)\n",
    "    print(scatter_matrix)\n",
    "\n",
    "print(scatter_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3]\n",
      " [3 0]\n",
      " [2 1]\n",
      " [0 2]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "data_set = [[ 3,  3,  1],\n",
    "            [ 3,  0,  1],\n",
    "            [ 2,  1,  1],\n",
    "            [ 0,  2,  1],\n",
    "            [-1,  1, -1],\n",
    "            [ 0,  0, -1],\n",
    "            [-1, -1, -1],\n",
    "            [ 1,  0, -1]]\n",
    "\n",
    "data_set = np.array(data_set)\n",
    "\n",
    "d = np.array([row[:-1] for row in data_set if row[-1]==1])\n",
    "\n",
    "print(d)\n",
    "print(type(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[ 8.75 -1.  ]\n",
    " [-1.    7.  ]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
